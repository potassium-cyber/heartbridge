import streamlit as st
import pandas as pd
from utils.db import get_posts
from utils.analysis import get_sentiment_analysis, get_word_frequencies, get_2d_sentiment_analysis
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import os

# è®¾ç½®ä¸­æ–‡å­—ä½“ (å°è¯•è§£å†³ Matplotlib ä¸­æ–‡ä¹±ç )
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'PingFang SC', 'Heiti TC', 'Droid Sans Fallback']
plt.rcParams['axes.unicode_minus'] = False 

def dashboard_page():
    st.title("ğŸ“Š ç§‘ç ”çœ‹æ¿ (Research Dashboard)")
    st.caption("åŸºäº NLP è‡ªç„¶è¯­è¨€å¤„ç†çš„ä»£é™…æ²Ÿé€šæ•°æ®åˆ†æ")

    df = get_posts()
    
    if df.empty:
        st.warning("æš‚æ— è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œåˆ†æï¼Œå¿«å»å¹¿åœºå‘å¸–å§ï¼")
        return

    # --- æ ¸å¿ƒæŒ‡æ ‡ ---
    avg_score, all_scores = get_sentiment_analysis(df)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ç¤¾åŒºæ€»å¸–å­æ•°", len(df))
    with col2:
        # æƒ…æ„Ÿåˆ†è½¬ä¸º 0-100 çš„â€œæ¸©æš–æŒ‡æ•°â€
        warmth_index = int(avg_score * 100)
        st.metric("ç¤¾åŒºæ¸©æƒ…æŒ‡æ•°", f"{warmth_index}%", delta=f"{warmth_index-50}%" if warmth_index != 50 else None)
    with col3:
        # ç»Ÿè®¡ç„¦è™‘å¸–å­çš„æ¯”ä¾‹ (å¾—åˆ†ä½äº 0.4 è§†ä¸ºæ½œåœ¨ç„¦è™‘)
        anxiety_count = len([s for s in all_scores if s < 0.4])
        anxiety_rate = int((anxiety_count / len(df)) * 100) if len(df) > 0 else 0
        st.metric("ç„¦è™‘æ„ŸçŸ¥æ¯”ä¾‹", f"{anxiety_rate}%")

    st.markdown("---")

    # --- ç§‘ç ”åŸç†è§£è¯» ---
    with st.expander("ğŸ“– æƒ…æ„Ÿåˆ†ææŠ€æœ¯åŸç†è§£è¯»"):
        st.markdown("""
        **Q: ä»€ä¹ˆæ˜¯â€œæ¸©æƒ…æŒ‡æ•°â€ï¼Ÿ**
        > æˆ‘ä»¬ä½¿ç”¨ NLP (è‡ªç„¶è¯­è¨€å¤„ç†) æŠ€æœ¯åˆ†æå¸–å­å†…å®¹çš„æƒ…æ„Ÿå€¾å‘ã€‚
        > * **0.0 - 0.2 (ç„¦è™‘/æ¶ˆæ)**: é€šå¸¸åŒ…å«å‹åŠ›ã€æŠ±æ€¨æˆ–æ±‚åŠ©çš„å…³é”®è¯ã€‚
        > * **0.4 - 0.6 (ä¸­æ€§/å¹³æ·¡)**: é™ˆè¿°äº‹å®ï¼Œæƒ…ç»ªæ³¢åŠ¨ä¸å¤§ã€‚
        > * **0.8 - 1.0 (æ¸©æš–/ç§¯æ)**: åŒ…å«é¼“åŠ±ã€æ„Ÿè°¢æˆ–å¼€å¿ƒçš„å†…å®¹ã€‚
        """)

    # --- ç§‘ç ”åˆ†ææ ¸å¿ƒåŒº ---
    st.markdown("### ğŸ“Š æ·±åº¦æƒ…æ„Ÿå¤šç»´åˆ†æ")
    
    col_left, col_right = st.columns([1, 1])

    with col_left:
        st.write("**ğŸ§­ æ·±åº¦å¿ƒç†æ¨¡å‹ (Russell ç¯çŠ¶å›¾)**")
        points = get_2d_sentiment_analysis(df)
        if points:
            fig_2d, ax_2d = plt.subplots(figsize=(5, 4)) # ç¼©å°å°ºå¯¸
            
            x_vals = [p['x'] for p in points]
            y_vals = [p['y'] for p in points]
            ax_2d.scatter(x_vals, y_vals, alpha=0.5, c='#636EFA', s=60)
            
            ax_2d.axhline(y=0.5, color='gray', linestyle='--', alpha=0.3)
            ax_2d.axvline(x=0.5, color='gray', linestyle='--', alpha=0.3)
            
            # ç¼©å°å­—ä½“ä»¥é€‚åº”å°å›¾
            font_size = 8
            ax_2d.text(0.2, 0.85, "ç„¦è™‘/æ„¤æ€’", color='#EF553B', fontsize=font_size, ha='center')
            ax_2d.text(0.8, 0.85, "å…´å¥‹/å¿«ä¹", color='#00CC96', fontsize=font_size, ha='center')
            ax_2d.text(0.2, 0.15, "æŠ‘éƒ/ç–²æƒ«", color='#19D3F3', fontsize=font_size, ha='center')
            ax_2d.text(0.8, 0.15, "å®‰è¯¦/æ”¾æ¾", color='#AB63FA', fontsize=font_size, ha='center')
            
            ax_2d.set_xlim(0, 1)
            ax_2d.set_ylim(0, 1)
            ax_2d.tick_params(axis='both', which='major', labelsize=7)
            st.pyplot(fig_2d)
        else:
            st.write("æ•°æ®åŠ è½½ä¸­...")

    with col_right:
        st.write("**ğŸ“ˆ ç¤¾åŒºæƒ…ç»ªåˆ†å¸ƒ (æ•ˆä»·åˆ†å¸ƒ)**")
        hist_df = pd.DataFrame(all_scores, columns=["sentiment"])
        if not hist_df.empty:
            counts = hist_df["sentiment"].value_counts(bins=5).sort_index()
            sentiment_labels = ["ğŸ˜© ç„¦è™‘", "ğŸ˜• çƒ¦æ¼", "ğŸ˜ å¹³æ·¡", "ğŸ™‚ æœŸå¾…", "ğŸ¥° æ¸©æš–"]
            
            if len(counts) == 5:
                chart_data = pd.DataFrame({"æ•°é‡": counts.values}, index=sentiment_labels)
            else:
                labels = [f"{idx.left:.1f}-{idx.right:.1f}" for idx in counts.index]
                chart_data = pd.DataFrame({"æ•°é‡": counts.values}, index=labels)

            st.bar_chart(chart_data, height=320) # é™åˆ¶é«˜åº¦
        else:
            st.write("æš‚æ— æ•°æ®")

    st.markdown("---")

    # --- è¯äº‘åŒº ---
    st.subheader("â˜ï¸ çƒ­é—¨è¯é¢˜è¯äº‘")
    word_counts = get_word_frequencies(df)
    if word_counts:
        # å°è¯•å¯»æ‰¾ä¸­æ–‡å­—ä½“
        font_path = None
        candidate_fonts = [
            '/System/Library/Fonts/STHeiti Light.ttc', 
            '/System/Library/Fonts/PingFang.ttc',
            '/usr/share/fonts/truetype/droid/DroidSansFallbackFull.ttf',
            'C:/Windows/Fonts/simhei.ttf'
        ]
        for path in candidate_fonts:
            if os.path.exists(path):
                font_path = path
                break
        
        try:
            wc = WordCloud(
                font_path=font_path,
                width=1000, height=300, # æ‰å¹³åŒ–ï¼Œé€‚åº”å®½åº¦
                background_color='white',
                max_words=100
            ).generate_from_frequencies(word_counts)

            fig_wc, ax_wc = plt.subplots(figsize=(10, 3))
            ax_wc.imshow(wc.to_image(), interpolation='bilinear')
            ax_wc.axis("off")
            st.pyplot(fig_wc)
        except Exception as e:
            st.error(f"è¯äº‘ç”Ÿæˆå¤±è´¥: {e}")
    
    # --- æ•°æ®é€è§† ---
    st.markdown("---")

    # --- æ•°æ®é€è§† ---
    st.markdown("---")
    st.subheader("ğŸ“‹ åŸå§‹æ•°æ®æ‘˜è¦ (ä»…ç§‘ç ”ç”¨é€”)")
    st.dataframe(df[['role', 'title', 'created_at']], use_container_width=True)
